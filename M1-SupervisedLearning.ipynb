{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9366ed7-0754-4261-a784-a2757639faed",
   "metadata": {},
   "source": [
    "# Module 1 - Binary Classification\n",
    "\n",
    "In this module you will explore some different classification techniques. By the end of this module you will be able to:\n",
    "\n",
    "- Apply 3 different classification models\n",
    "- Identify different scoring metrics\n",
    "- Compare the results from different classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40902563-ed5c-4041-a015-0034e8ccf48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we start, let's import all the different packages that we are going to use for this module\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0c5251-3945-45f5-8838-f4daa4db85bb",
   "metadata": {},
   "source": [
    "**Data**\n",
    "\n",
    "For this module, we will use a dataset containing the diagnostic of multiple Breast Cancer tests in Wisconsin. More information about this dataset can be found in the following [link](https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic).\n",
    "\n",
    "Let's start by creating our df and doing some data pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3379b0e7-1b4f-4a08-9802-b289a299c977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Feature 2</th>\n",
       "      <th>Feature 3</th>\n",
       "      <th>Feature 4</th>\n",
       "      <th>Feature 5</th>\n",
       "      <th>Feature 6</th>\n",
       "      <th>Feature 7</th>\n",
       "      <th>Feature 8</th>\n",
       "      <th>Feature 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature 22</th>\n",
       "      <th>Feature 23</th>\n",
       "      <th>Feature 24</th>\n",
       "      <th>Feature 25</th>\n",
       "      <th>Feature 26</th>\n",
       "      <th>Feature 27</th>\n",
       "      <th>Feature 28</th>\n",
       "      <th>Feature 29</th>\n",
       "      <th>Feature 30</th>\n",
       "      <th>Feature 31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>1</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>1</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>1</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>1</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>0</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  Diagnosis  Feature 2  Feature 3  Feature 4  Feature 5  \\\n",
       "0      842302          1      17.99      10.38     122.80     1001.0   \n",
       "1      842517          1      20.57      17.77     132.90     1326.0   \n",
       "2    84300903          1      19.69      21.25     130.00     1203.0   \n",
       "3    84348301          1      11.42      20.38      77.58      386.1   \n",
       "4    84358402          1      20.29      14.34     135.10     1297.0   \n",
       "..        ...        ...        ...        ...        ...        ...   \n",
       "564    926424          1      21.56      22.39     142.00     1479.0   \n",
       "565    926682          1      20.13      28.25     131.20     1261.0   \n",
       "566    926954          1      16.60      28.08     108.30      858.1   \n",
       "567    927241          1      20.60      29.33     140.10     1265.0   \n",
       "568     92751          0       7.76      24.54      47.92      181.0   \n",
       "\n",
       "     Feature 6  Feature 7  Feature 8  Feature 9  ...  Feature 22  Feature 23  \\\n",
       "0      0.11840    0.27760    0.30010    0.14710  ...      25.380       17.33   \n",
       "1      0.08474    0.07864    0.08690    0.07017  ...      24.990       23.41   \n",
       "2      0.10960    0.15990    0.19740    0.12790  ...      23.570       25.53   \n",
       "3      0.14250    0.28390    0.24140    0.10520  ...      14.910       26.50   \n",
       "4      0.10030    0.13280    0.19800    0.10430  ...      22.540       16.67   \n",
       "..         ...        ...        ...        ...  ...         ...         ...   \n",
       "564    0.11100    0.11590    0.24390    0.13890  ...      25.450       26.40   \n",
       "565    0.09780    0.10340    0.14400    0.09791  ...      23.690       38.25   \n",
       "566    0.08455    0.10230    0.09251    0.05302  ...      18.980       34.12   \n",
       "567    0.11780    0.27700    0.35140    0.15200  ...      25.740       39.42   \n",
       "568    0.05263    0.04362    0.00000    0.00000  ...       9.456       30.37   \n",
       "\n",
       "     Feature 24  Feature 25  Feature 26  Feature 27  Feature 28  Feature 29  \\\n",
       "0        184.60      2019.0     0.16220     0.66560      0.7119      0.2654   \n",
       "1        158.80      1956.0     0.12380     0.18660      0.2416      0.1860   \n",
       "2        152.50      1709.0     0.14440     0.42450      0.4504      0.2430   \n",
       "3         98.87       567.7     0.20980     0.86630      0.6869      0.2575   \n",
       "4        152.20      1575.0     0.13740     0.20500      0.4000      0.1625   \n",
       "..          ...         ...         ...         ...         ...         ...   \n",
       "564      166.10      2027.0     0.14100     0.21130      0.4107      0.2216   \n",
       "565      155.00      1731.0     0.11660     0.19220      0.3215      0.1628   \n",
       "566      126.70      1124.0     0.11390     0.30940      0.3403      0.1418   \n",
       "567      184.60      1821.0     0.16500     0.86810      0.9387      0.2650   \n",
       "568       59.16       268.6     0.08996     0.06444      0.0000      0.0000   \n",
       "\n",
       "     Feature 30  Feature 31  \n",
       "0        0.4601     0.11890  \n",
       "1        0.2750     0.08902  \n",
       "2        0.3613     0.08758  \n",
       "3        0.6638     0.17300  \n",
       "4        0.2364     0.07678  \n",
       "..          ...         ...  \n",
       "564      0.2060     0.07115  \n",
       "565      0.2572     0.06637  \n",
       "566      0.2218     0.07820  \n",
       "567      0.4087     0.12400  \n",
       "568      0.2871     0.07039  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading df\n",
    "df = pd.read_csv(\"datasets/wdbc.data\", header=None)\n",
    "df.columns = ['ID', 'Diagnosis'] + [f'Feature {i}' for i in range(2, len(df.columns))]\n",
    "# As our target is to predict Malign cancer, we are going to set M in Diagnosis as 1 and Benign as 0\n",
    "df[\"Diagnosis\"] = np.where(df[\"Diagnosis\"] == \"M\",1,0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68dee8f1-5056-4c91-b61b-f46740fc7964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to create our training and testing df's. We are going to use a conventional 80-20 split. \n",
    "X = df.drop([\"ID\",\"Diagnosis\"],axis=1)\n",
    "y = df[\"Diagnosis\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef41cf24-a528-4044-b093-8140d99ceff3",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "We will start by applying some classification algorithms and evaluate their performance. \n",
    "\n",
    "### SVM\n",
    "\n",
    "This algorith attempts to find the hyperplane that better separates the data. To learn more about the model and methods used in the following lines of code, you can go to the [source documentation](https://scikit-learn.org/stable/modules/svm.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "188033e7-97c8-417e-a577-738c35319ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import out model class from the source library\n",
    "from sklearn import svm\n",
    "# Creating our svm classifier\n",
    "svm_clf = svm.SVC()\n",
    "# Fitting our model\n",
    "svm_clf.fit(X_train, y_train)\n",
    "# Predictions\n",
    "svm_predictions = svm_clf.predict(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a911127-1632-451b-89d4-bb1e392bf78d",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier\n",
    "\n",
    "Now, let's fit a booster classifier. To learn more about the model and methods used in the following lines of code, you can go to the [source documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "544c8001-79ea-466e-8fb9-396d5457e794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import out model class from the source library\n",
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "# Creating our GB classifier\n",
    "gb_clf = GradientBoostingClassifier() \n",
    "# Fitting our model\n",
    "gb_clf.fit(X_train, y_train)\n",
    "# Predictions \n",
    "gb_predictions = gb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848d57ad-e7ad-4e65-b4d4-7e7f6682183d",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "### Logistic Regression\n",
    "\n",
    "Now, let's proceed with a Logistic Regression approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd3d1e67-3448-41bf-86bc-45e80d3cafff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import out model class from the source library\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "# Creating our LR classifier\n",
    "lr_clf = LogisticRegression(max_iter=1800)\n",
    "# Fitting our model\n",
    "lr_clf.fit(X_train, y_train)\n",
    "# Predictions \n",
    "lr_predictions = lr_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282ae0ef-a819-4091-8fe4-b855230a83f1",
   "metadata": {},
   "source": [
    "## Evaluating our models\n",
    "\n",
    "So far we have made predictions used 3 different model approaches. How do we know which model did a better job in predicting our target value? There are two metrics we are going to put attention to:\n",
    "\n",
    "- **Accuracy:** This metric tells us the ratio of good predictions, by dividing the number of correctly predicted values over the total observed values. In formula terms:\n",
    "$$\n",
    "A = \\frac{TruePositives + TrueNegatives}{TruePositives+TrueNegatives+FalsePositives+FalseNegatives}\n",
    "$$\n",
    "\n",
    "- **Precision:** In this metric we are only putting attention to the ability of our models to predict the positives, by dividing the number of correct positives over the number of totally predicted positives. In formula terms:\n",
    "$$\n",
    "P = \\frac{TruePositives}{TruePositives+FalsePositives}\n",
    "$$\n",
    "\n",
    "Now we are going to compare our three classification models by using these metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ced72d51-ecda-4a1b-bb6d-c732c5e171d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 92.0%\n",
      "SVM Precision: 100.0%\n",
      "\n",
      "GB Accuracy: 96.0%\n",
      "GB Precision: 97.0%\n",
      "\n",
      "LR Accuracy: 96.0%\n",
      "LR Precision: 97.0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "\n",
    "# SVM\n",
    "svm_accuracy = round(accuracy_score(y_test,svm_predictions),2)\n",
    "svm_precision = round(precision_score(y_test, svm_predictions),2)\n",
    "\n",
    "# GB\n",
    "gb_accuracy = round(accuracy_score(y_test,gb_predictions),2)\n",
    "gb_precision = round(precision_score(y_test, gb_predictions),2)\n",
    "\n",
    "# LR\n",
    "lr_accuracy = round(accuracy_score(y_test,lr_predictions),2)\n",
    "lr_precision = round(precision_score(y_test, lr_predictions),2)\n",
    "\n",
    "print(f\"SVM Accuracy: {svm_accuracy*100}%\")\n",
    "print(f\"SVM Precision: {svm_precision*100}%\\n\")\n",
    "print(f\"GB Accuracy: {gb_accuracy*100}%\")\n",
    "print(f\"GB Precision: {gb_precision*100}%\\n\")\n",
    "print(f\"LR Accuracy: {lr_accuracy*100}%\")\n",
    "print(f\"LR Precision: {lr_precision*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b64a205-b316-4731-a14b-b4a794a399ae",
   "metadata": {},
   "source": [
    "## Hands-on\n",
    "\n",
    "Now it's your turn to test the models that we have covered and so far and compare their performance on a different dataset. For this task, you are going to use a different dataset. \n",
    "\n",
    "Your tasks are the following:\n",
    "\n",
    "1. Load the dataset and perform any necessary analysis, cleaning and pre-processing.\n",
    "2. Fit each of the 3 models we covered in this module.\n",
    "3. Evaluate the 3 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9690bb6-b8bb-40ce-a787-0771e98f5fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
